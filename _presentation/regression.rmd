
---

name: reg
# Regression linéaire 

---
template: reg
## Etude de la pollution au SO2

On a mesuré pour 41 villes américaines, la pollution au SO2 ainsi que la population dans la ville


```{r usfata, eval = TRUE, echo = c(1,2), warning = FALSE, out.width = '30%'}
library(coursesdata)
data(usdata)
usdata %>% ggplot() +  aes(x= pop, y = SO2)+  geom_point()
```


--
<p class="question"> La taille d'une ville est-elle liée à la pollution en SO2 ?</p>


---
template: reg
## Cadre général du modèle de régression simple

On étudie le lien entre  
- une variable quantitative notée $Y$ (l'indicateur de SO2),
- et une variable quantitative $x$.

Les données peuvent être visualisées à l'aide d'un nuage de points.


--
<p class="question"> La variable x permet elle d'expliquer la variabilité de la variable Y ?</p>

---
name: model
# Regression linéaire 
## Le modèle de régression simple

---
template: model

### Graphiquement 

Une visualisation graphique du modèle d'analyse de régression simple

<br> <br> <br> <br>


Comment imagine-t-on le processus aléatoire qui a conduit à nos données ?




---

```{r reg_versiongraphique_prep, eval = TRUE, echo = FALSE}
set.seed(222)
n <- 20
x <- round(rnorm(n, mean= 10, sd = 2),2)
beta0 <- 1
beta1 <- 0.5
sigma <- 1
fake_dta <- tibble(x= x, y = rnorm(n, mean = beta0 + beta1*x, sd =sigma))  

x0 <-  x[4]
norm_dta <- tibble::tibble(y = rnorm(1000, mean=beta0 + beta1*x0, sd= sigma), x= x0 + dnorm(x = y- beta0 - beta1*x0, mean= 0,  sd=0.5))

norm_dta0 <- tibble::tibble(y = rnorm(1000, mean=mean(fake_dta$y), sd= sigma), x= x0 + dnorm(x = y - mean(fake_dta$y), mean= 0,  sd=0.5))
```


```{r reg_versiongraphique, echo = FALSE , eval = FALSE, warning=FALSE, message = FALSE}
ggplot(data=fake_dta) + 
  ylab('y') + 
  xlim(c(min(fake_dta$x-0.5), max(fake_dta$x+ 0.5))) + 
  ylim(c(min(fake_dta$y-1.5), max(fake_dta$y+ 1.5))) +
  ggtitle('Modèle Mcomp') +
  geom_abline(slope = beta1, intercept = beta0) + #BREAK
  geom_point(x=x0, y=beta0+beta1*x0, col = 'red', size=2) + #BREAK
  geom_point(data=norm_dta, aes(y=y, x=x), col = 'red', alpha=0.02) + #BREAK
  geom_point(aes(x=x, y=y)) 
```

`r chunk_reveal("reg_versiongraphique", break_type = "user", display_type="output")`

---


```{r reg_versiongraphique_M0, echo = FALSE, eval = FALSE, warning=FALSE, message = FALSE}
ggplot(data=fake_dta) + 
  xlim(c(min(fake_dta$x-0.5), max(fake_dta$x+ 0.5))) + 
  ylim(c(min(fake_dta$y-1.5), max(fake_dta$y+ 1.5))) +
  ylab('y') + 
  ggtitle('Modèle nul') +
  geom_abline(slope = 0, intercept = mean(fake_dta$y)) + #BREAK
  geom_point(x=x0, y = mean(fake_dta$y), col = 'red', size=2) + #BREAK
  geom_point(data=norm_dta0, aes(y=y, x=x), col = 'red', alpha=0.02) + #BREAK
  geom_point(aes(x=x, y=y)) 
```


`r chunk_reveal("reg_versiongraphique_M0", break_type = "user", display_type="output")`




```{r reg_versiongraphique_save, eval = TRUE, echo = FALSE, warnings = FALSE, message =FALSE}
pM0 <- ggplot(data=fake_dta) + 
  ylab('y') + 
  xlim(c(min(fake_dta$x-0.5), max(fake_dta$x+ 0.5))) + 
  ylim(c(min(fake_dta$y-1.5), max(fake_dta$y+ 1.5))) +
  ggtitle('Modèle nul') +
  geom_abline(slope = 0, intercept = mean(fake_dta$y)) + #BREAK
  geom_point(x=x0, y = mean(fake_dta$y), col = 'red', size=2) + #BREAK
  geom_point(data=norm_dta0, aes(y=y, x=x), col = 'red', alpha=0.02) + #BREAK
  geom_point(aes(x=x, y=y)) 
pMcomp <- ggplot(data=fake_dta) + 
  ylab('y') + 
  xlim(c(min(fake_dta$x-0.5), max(fake_dta$x+ 0.5))) + 
  ylim(c(min(fake_dta$y-1.5), max(fake_dta$y+ 1.5))) +
  ggtitle('Modèle Mcomp') +
  geom_abline(slope = beta1, intercept = beta0) + #BREAK
  geom_point(x=x0, y=beta0+beta1*x0, col = 'red', size=2) + #BREAK
  geom_point(data=norm_dta, aes(y=y, x=x), col = 'red', alpha=0.02) + #BREAK
  geom_point(aes(x=x, y=y)) 
```


---
template: model

Lequel de ces mécanismes est le plus crédible au vu des donées ?

```{r compare_model_graph, eval = TRUE, echo = FALSE, warnings = FALSE,message =FALSE,  fig.width=12, fig.height = 8}
ggpubr::ggarrange(pMcomp, pM0, nrow = 1, common.legend = TRUE)
```

---
template: model

$$Y_{k} = \beta_0 +\beta_1 x_{k}  +E_{k},\quad E_{k}\overset{ind}{\sim}\mathcal{N}(0, \sigma^2),$$
avec 
- $x_k$ la valeur de la variable explicative pour l'observation $k$, 
- $k=1,\ldots,n$ le numéro d'individu, $n$ le nombre total d'individus,
- $\beta_0$ l'ordonnée à l'origine, 
- $\beta_1$ la pente de la droite, mesure de l'effet de la variable $x$

- $\sigma^2$ la variance.

### Une écriture équivalente 

$$Y_{k} \overset{ind}{\sim}\mathcal{N}(\beta_0+\beta_1 x_k, \sigma^2).$$


### Nombre de paramètres du modèle

- $2$ paramètres de moyenne  $(\beta_0, \beta_1)$; 
- 1 paramètre de variance $\sigma^2$

---
template: model

## Le modèle de régression simple sur l'exemple de la pollution.

$$Y_{k} = \beta_0 +\beta_1 x_{k}  +E_{k},\quad E_{k}\overset{ind}{\sim}\mathcal{N}(0, \sigma^2),$$
avec 
- $x_k$ la population dans la ville $k$, 
- $k=1,\ldots,n$ le numéro de la ville, $n=41$,
- $\beta_0$ l'ordonnée à l'origine, 
- $\beta_1$ la pente de la droite, mesure de l'effet de la population sur la pollution.

- $\sigma^2$ la variance.

### Nombre de paramètres du modèle
- 2 paramètres de moyennes
- 1 paramètre de variance

---
name: parametre
# Regression linéaire
## Estimation des paramètres 

---
template: parametre

### Version mathématique

hors programme !

---
template: parametre
### Version pratique

```{r reg-simple}
Mpop <- lm(SO2~pop, data = usdata)
summary(Mpop)
```



---
name: prediction
# Regeression linéaire
## Prediction avec un modèle de régression simple

---
template:  prediction
Il est fréquent d'utiliser un modèle de régression pour prédire. 

### Prédiction de la valeur moyenne pour un $x$ particulier

**Valeur moyenne attendue pour $y$ pour un $x$ donné**
$\beta_0+\beta_1 x.$

**Valeur moyenne prédite pour $y$ pour un $x$ donné**
$\hat{\beta}_0+\hat{\beta}_1 x.$

```{r pred, eval = TRUE, echo = TRUE}
predict(Mpop, newdata=data.frame(pop=333))
```

### Intervalle de confiance pour la valeur moyenne prédite  pour $y$ pour un $x$ donné
$\hat{\beta}_0+\hat{\beta}_1 x.$

```{r pred_IC, eval = TRUE, echo = TRUE}
predict(Mpop, newdata=data.frame(pop=333), interval = 'confidence')
```

---
template:  prediction
Il est fréquent d'utiliser un modèle de régression pour prédire. 

### Prédiction de la valeur possible $y$ pour un  $x$ particulier

```{r pred_x, eval = TRUE, echo = TRUE}
predict(Mpop, newdata=data.frame(pop=333), interval = 'prediction')
```

---
template:  prediction
### Sur l'exemple de la polution

**Intervalle de confiance pour le comportement moyen**


```{r predic_plot, eval = TRUE, echo = FALSE}
ggplot(usdata) + aes(x=pop, y= SO2 ) + geom_point() + geom_smooth(method= 'lm', se = TRUE)

```


---
count: false
template:  prediction
### Sur l'exemple de la polution

**Intervalle de confiance pour le comportement moyen**

```{r predic_plot_pred, eval = TRUE, echo = FALSE}
pred_interval <- predict(Mpop,  interval="prediction", level = 0.95)
pred_interval <- as.data.frame(pred_interval) %>% mutate(pop=usdata$pop) %>% arrange(pop)

ggplot(usdata) + geom_point(aes(x=pop, y= SO2 ) )  + 
  geom_ribbon(data=pred_interval, aes(x = pop, ymin = lwr, ymax = upr), fill = "blue", alpha = 0.1) + geom_smooth(method= 'lm', se = TRUE, aes(x=pop, y= SO2 ) )
```

---
name: model
# Modèle de régression multiple

---
template: model

## Le modèle de régression multiple

Plusieurs variables sont potentiellement liées à la pollution en SO2


- temp : Average temperature in Fahrenheit
- manuf : No. of companies employing more than 20 employees
- pop : Population in thousands
- wind : Average annual wind speed in miles/hour
- precip : annual precipitation height in inches
- days : No. of days of precipitation


<a class=question> Quelles sont les variables liées à la pollution en SO2 ? </a>




---
template: model

## Le modèle de régression multiple 

$$Y_{k} = \beta_0 +\beta_1 x_{k}^{1}  + \beta_2 x_{k}^{2} + \ldots +  \beta_p x_{k}^{p}  +  E_{k},\quad E_{k}\overset{ind}{\sim}\mathcal{N}(0, \sigma^2),$$
avec 
- $x_{k}^{l}$ la valeur de la variable explicative $l$ pour l'observation $k$, 
- $k=1,\ldots,n$ le numéro d'individu, $n$ le nombre total d'individus,
- $\beta_0$ l'ordonnée à l'origine, 
- $\beta_l$ l'effet de la variable $X^{l}$ sur la variable à expliquer,
- $\sigma^2$ la variance.

### Une écriture équivalente 

$$Y_{k} \overset{ind}{\sim}\mathcal{N}(\beta_0 +\beta_1 x_{k}^{1}  + \beta_2 x_{k}^{2} + \ldots +  \beta_p x_{k}^{p} , \sigma^2).$$


### Nombre de paramètres du modèle

- $l+1$ paramètres de moyenne  $(\beta_0, \beta_1, \ldots, \beta_l)$; 
- 1 paramètre de variance $\sigma^2$


---
template: model

### Sur l'exemple de la pollution


```{r m_comp_mult, eval = TRUE, echo = TRUE, out.width="100%"}
Mcomp <- lm(SO2 ~ temp + manuf + pop + wind + precip + days, data = usdata) 
#Mcomp <- lm(SO2 ~ . - City , data = usdata) # toutes les variables sauf City
model.matrix(Mcomp) %>% head(n = 3)
```
---
name: parametre
# Regression linéaire multiple
## Estimation des paramètres


---
template: parametre
### Estimation des paramètres du modèle version mathématique

hors programme 

### Estimation des paramètres du modèle version pratique

```{r reg-mult, echo = TRUE, eval = TRUE}
Mcomp<- lm(SO2~ temp +  manuf + pop + wind +  precip + days, data = usdata)
summary(Mcomp)
```


---
template: parametre
### Estimation des paramètres du modèle version mathématique

hors programme 

### Estimation des paramètres du modèle version mathématique
On ne peut prendre en compte que certaines  variables

Exemple

```{r reg-mult-12, echo = TRUE, eval = TRUE}
M12<- lm(SO2~pop + wind, data = usdata)
summary(M12)
```



---
name: modcomp
# Regression multiple 
## Test du modèle complet


---
template: modcomp
## Pollution 

<p class="question"> La pollution en SO2 dans les villes américaines est elles liées à l'une au moins des variables caractérisiques des villes ?</p>


--

On va à la pêche ....

---
template: modcomp
### Sous forme de comparaison de modèle


```{r compare_model_graph2, ref.label='compare_model_graph', eval = TRUE, echo = FALSE, results='markup'}
```

--
<p class="question"> Le modèle Mcomp est il plus pertinent que le modèle M0 ?</p>



---
template: modcomp
### Hypothèses du test

On va donc opposer une hypothèse de travail $H_0$ contre une hypothèse alternative $H_1$. $H_0$ peut donc prendre différentes formes:


$$\begin{align} 
H_0 & =\left \lbrace \mbox{Auncune variable n'est liée à la pollution en SO2}\right\rbrace\\
    & =\left \lbrace  \mbox{pour tout }p\geq 1, \beta_p =0   \right\rbrace\\
    & =\left \lbrace  M_{comp} \mbox{ est équivalent à } M0 \right\rbrace.
\end{align}$$


$H_1$ prend les formes équivalentes suivantes

$$\begin{align} 
H_1 & =\left \lbrace \mbox{Au moins 1 variable est liée à la pollution en SO2}\right\rbrace\\
    & =\left \lbrace  \mbox{Il existe un } p, \beta_p \ne 0  \right\rbrace\\
    & =\left \lbrace  M_{comp} \mbox{ est préférable à } M0 \right\rbrace.
\end{align}$$

--

Sous $H_0$, 
$$F= \frac{\frac{SS_{M_{comp}}}{l}}{\frac{RSS}{n-l-1}} \underset{H_0}{\sim}\mathcal{F}(l, n-l-1)$$  

---
template: modcomp
### Loi de la statistique de test sous $H_0$ - graphiquement

Sous $H_0$ la loi de distribution de $F$ est 

```{r p_value-reg,echo = FALSE,  eval = TRUE}
tibble(x = seq(0, 10, length.out = 2001)) %>% 
  mutate(y = df(x, df1 = 4, df= 38)) -> chi_dta
Fobs <- 1
chi_dta %>% filter(x> Fobs) %>% add_row(x=100,y = 0) %>%  add_row(x=Fobs, y =0)  %>% 
  add_row(x=Fobs, y =df(Fobs, df1 = 4, df= 38)) %>% arrange(x,y)  -> chi_dta_poly
```


```{r pvalue_graphique-reg, echo = FALSE, eval = FALSE}
ggplot(data  = chi_dta) + xlab('y') + ylab('density') + geom_line(aes(x=x, y=y)) + #BREAK
  annotate("text", x = Fobs- 0.5, y = 0.05, label = "Fobs", col = 'red')+  geom_vline(aes(xintercept = Fobs), col = 'red') + #BREAK
  geom_polygon(data = chi_dta_poly,  aes(x=x, y= y), alpha = 0.3) + xlim(c(0, max(chi_dta$x))) 

```

---

`r chunk_reveal("pvalue_graphique-reg", break_type = "user", display_type="output")`

---
name: test_variable
# Regression multiple 
## Test de l'effet des variables

---
template: test_variable

### Test sur les paramètres

Tester la nullité du paramètre $\beta_l$ revient à tester si la variable $x^{l}$ et la variable $Y$ sont liées.


--

Ce test est similaire  au test de comparaison entre le modèle complet et le modèle complet privé de la variable $x^{l}$.


---
count: false
template: test_variable

### Equivalence des tests sur l'exemple de la pollution


```{r car, echo=FALSE, eval=TRUE}
library(car)
```

```{r pol_mult, eval = TRUE}
summary(Mcomp)$coefficients
Mcomp_l <- lm(SO2 ~  temp + manuf +  wind + precip + days, data = usdata) 
anova(Mcomp_l, Mcomp)
```

### Lien entre les statistiques  de tests

```{r stu2, eval = TRUE, echo =TRUE}
res <- summary(Mcomp)$coefficients
res[,"t value"]^2
```

---
template: test_variable
## Vigilance sur l'interprétation des tests


```{r test_inter, eval =TRUE}
summary(Mcomp)$coefficients
```

--
```{r ggpairs, eval = TRUE}
GGally::ggpairs(usdata, columns = 2:8)
```


```{r ggplot_back, echo = FALSE, eval = TRUE}
ggplot <- function(...) ggplot2::ggplot(...) 
```

